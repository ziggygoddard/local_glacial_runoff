{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0815b9-0798-4e2b-b23a-c02a0de7843d",
   "metadata": {},
   "source": [
    "# Glacier runoff model for La Paz, Bolivia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd2866-1500-4a60-b06c-83fb99db3a9a",
   "metadata": {},
   "source": [
    "Current questions/issues:\n",
    "- Unsure if glacier directory is up to date\n",
    "- Continue on error is on (we didn't figure out how to avoid this)\n",
    "- Multiprocessing is off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec844b-90d7-47ea-8416-272d27e7fc85",
   "metadata": {},
   "source": [
    "## <b> Step 1: Import necessary software packages for graphing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1729f9a-1399-4909-a7b6-93c4208665d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import shapely.geometry as shpg\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25242f1-2077-49a2-ba16-49a93cd4e85a",
   "metadata": {},
   "source": [
    "## <b> Step 2: import and set up OGGM software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de469965-7f43-4385-aa8f-fefd67b03c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oggm import cfg, utils, workflow, tasks, graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4449cefc-18ea-4d6d-ade7-0cd6ed735bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path in your home directory\n",
    "path = '/Users/ziggygoddard/Documents/summer24/OGGM_output' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934ab118-4065-4268-997f-a0c8f845ba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 16:41:18: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2024-06-19 16:41:18: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2024-06-19 16:41:18: oggm.cfg: Multiprocessing: using all available processors (N=8)\n",
      "2024-06-19 16:41:20: oggm.cfg: PARAMS['store_model_geometry'] changed from `False` to `True`.\n",
      "2024-06-19 16:41:20: oggm.cfg: PARAMS['continue_on_error'] changed from `False` to `True`.\n"
     ]
    }
   ],
   "source": [
    "# work with parameters \n",
    "cfg.initialize(logging_level='WARNING')\n",
    "cfg.PATHS['working_dir']=path\n",
    "\n",
    "cfg.PARAMS['store_model_geometry'] = True\n",
    "# cfg.PARAMS['use_multiprocessing'] = True\n",
    "cfg.PARAMS['continue_on_error']=True #this is to avoid issues with the files with invalid geometries\n",
    "\n",
    "#You can provide any other dataset to OGGM by setting the climate_file parameter in params.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfbca44-ca4d-449b-b352-d833d03aa7b9",
   "metadata": {},
   "source": [
    "## Step 3: Define glaciers for the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042afaea-80fb-49af-8d0e-b418d190f265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ziggygoddard/OGGM/rgi/RGIV62'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download glacier outlines\n",
    "# I assume I should access a newer version of the glacier directory?\n",
    "utils.get_rgi_dir(version='62')  # path to the data after download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3eedbb6-12b9-429e-a465-278f8b1cf552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rgi region file for region 16 (South America)\n",
    "# Update?\n",
    "fr = utils.get_rgi_region_file(16, version='62')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e52547-3f48-4bff-82d8-373d6537818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file as as geopandas\n",
    "gdf = gpd.read_file(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "075f1224-ac56-438f-b987-5e0dd59d32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add basin shapefile\n",
    "path = '~/Documents/summer24/LaPaz_dissolved.shp' # Is this what I want? Is it up to date?\n",
    "basin = gpd.read_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e58b3dc-c9f7-4e07-b21e-186207bc2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select glaciers within the basin\n",
    "in_bas = [basin.geometry.contains(shpg.Point(x, y))[0] for\n",
    "          (x, y) in zip(gdf.CenLon, gdf.CenLat)]\n",
    "gdf_sel = gdf.loc[in_bas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d82b028-0836-4ce4-abee-6aaaaf98325e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select rgi id's from the gdf_sel file\n",
    "rgi_ids = gdf_sel['RGIId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06151fa2-7e08-4193-b9df-1e71f5a27885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494     RGI60-16.00495\n",
       "496     RGI60-16.00497\n",
       "497     RGI60-16.00498\n",
       "500     RGI60-16.00501\n",
       "504     RGI60-16.00505\n",
       "505     RGI60-16.00506\n",
       "507     RGI60-16.00508\n",
       "508     RGI60-16.00509\n",
       "509     RGI60-16.00510\n",
       "510     RGI60-16.00511\n",
       "512     RGI60-16.00513\n",
       "522     RGI60-16.00523\n",
       "523     RGI60-16.00524\n",
       "525     RGI60-16.00526\n",
       "527     RGI60-16.00528\n",
       "529     RGI60-16.00530\n",
       "530     RGI60-16.00531\n",
       "531     RGI60-16.00532\n",
       "538     RGI60-16.00539\n",
       "539     RGI60-16.00540\n",
       "543     RGI60-16.00544\n",
       "544     RGI60-16.00545\n",
       "545     RGI60-16.00546\n",
       "546     RGI60-16.00547\n",
       "548     RGI60-16.00549\n",
       "549     RGI60-16.00550\n",
       "563     RGI60-16.00564\n",
       "565     RGI60-16.00566\n",
       "594     RGI60-16.00595\n",
       "595     RGI60-16.00596\n",
       "609     RGI60-16.00610\n",
       "610     RGI60-16.00611\n",
       "1441    RGI60-16.01447\n",
       "1442    RGI60-16.01448\n",
       "1443    RGI60-16.01449\n",
       "Name: RGIId, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgi_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e0c71-f806-4525-b3e4-84a5d0874be4",
   "metadata": {},
   "source": [
    "## Step 4. Prepare glacier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c11d9b-c968-4def-9c80-9f621fb06f83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 16:41:23: oggm.workflow: init_glacier_directories from prepro level 5 on 35 glaciers.\n",
      "2024-06-19 16:41:23: oggm.workflow: Execute entity tasks [gdir_from_prepro] on 35 glaciers\n",
      "2024-06-19 16:41:23: oggm.workflow: WARNING: you are trying to run an entity task on 35 glaciers with multiprocessing turned off. OGGM will run faster with multiprocessing turned on.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initiate glacier directory task for each glacier\u001b[39;00m\n\u001b[1;32m      2\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/elev_bands/W5E5_spinup\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m gdirs \u001b[38;5;241m=\u001b[39m workflow\u001b[38;5;241m.\u001b[39minit_glacier_directories(rgi_ids,\n\u001b[1;32m      4\u001b[0m                                            from_prepro_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      5\u001b[0m                                            prepro_base_url\u001b[38;5;241m=\u001b[39mbase_url,\n\u001b[1;32m      6\u001b[0m                                          prepro_border\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/oggm/workflow.py:426\u001b[0m, in \u001b[0;36minit_glacier_directories\u001b[0;34m(rgidf, reset, force, from_prepro_level, prepro_border, prepro_rgi_version, prepro_base_url, from_tar, delete_tar)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mPARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdl_verify\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    425\u001b[0m         utils\u001b[38;5;241m.\u001b[39mget_dl_verify_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster.klima.uni-bremen.de\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 426\u001b[0m     gdirs \u001b[38;5;241m=\u001b[39m execute_entity_task(gdir_from_prepro, entities,\n\u001b[1;32m    427\u001b[0m                                 from_prepro_level\u001b[38;5;241m=\u001b[39mfrom_prepro_level,\n\u001b[1;32m    428\u001b[0m                                 prepro_border\u001b[38;5;241m=\u001b[39mprepro_border,\n\u001b[1;32m    429\u001b[0m                                 prepro_rgi_version\u001b[38;5;241m=\u001b[39mprepro_rgi_version,\n\u001b[1;32m    430\u001b[0m                                 base_url\u001b[38;5;241m=\u001b[39mprepro_base_url)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# We can set the intersects file automatically here\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (cfg\u001b[38;5;241m.\u001b[39mPARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_intersects\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    434\u001b[0m             \u001b[38;5;28mlen\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mPARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintersects_gdf\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    435\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m from_tar):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/oggm/workflow.py:191\u001b[0m, in \u001b[0;36mexecute_entity_task\u001b[0;34m(task, gdirs, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ng \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    188\u001b[0m         log\u001b[38;5;241m.\u001b[39mworkflow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWARNING: you are trying to run an entity task on \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    189\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m glaciers with multiprocessing turned off. OGGM \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    190\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill run faster with multiprocessing turned on.\u001b[39m\u001b[38;5;124m'\u001b[39m, ng)\n\u001b[0;32m--> 191\u001b[0m     out \u001b[38;5;241m=\u001b[39m [pc(gdir) \u001b[38;5;28;01mfor\u001b[39;00m gdir \u001b[38;5;129;01min\u001b[39;00m gdirs]\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/oggm/workflow.py:108\u001b[0m, in \u001b[0;36m_pickle_copier.__call__\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_func:\n\u001b[1;32m    107\u001b[0m     func, kwargs \u001b[38;5;241m=\u001b[39m func\n\u001b[0;32m--> 108\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_internal(func, arg, kwargs)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/oggm/workflow.py:102\u001b[0m, in \u001b[0;36m_pickle_copier._call_internal\u001b[0;34m(self, call_func, gdir, kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     gdir, gdir_kwargs \u001b[38;5;241m=\u001b[39m gdir\n\u001b[1;32m    100\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(gdir_kwargs)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call_func(gdir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/oggm/workflow.py:255\u001b[0m, in \u001b[0;36mgdir_from_prepro\u001b[0;34m(entity, from_prepro_level, prepro_border, prepro_rgi_version, base_url)\u001b[0m\n\u001b[1;32m    252\u001b[0m tar_base \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mget_prepro_gdir(prepro_rgi_version, rid, prepro_border,\n\u001b[1;32m    253\u001b[0m                                  from_prepro_level, base_url\u001b[38;5;241m=\u001b[39mbase_url)\n\u001b[1;32m    254\u001b[0m from_tar \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tar_base\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), rid \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tar.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m oggm\u001b[38;5;241m.\u001b[39mGlacierDirectory(entity, from_tar\u001b[38;5;241m=\u001b[39mfrom_tar)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/oggm/utils/_workflow.py:2646\u001b[0m, in \u001b[0;36mGlacierDirectory.__init__\u001b[0;34m(self, rgi_entity, base_dir, reset, from_tar, delete_tar)\u001b[0m\n\u001b[1;32m   2643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2644\u001b[0m     _shp \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, rgi_entity[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m], rgi_entity[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m   2645\u001b[0m                         rgi_entity, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutlines.shp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2646\u001b[0m rgi_entity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_shapefile_from_path(_shp)\n\u001b[1;32m   2647\u001b[0m crs \u001b[38;5;241m=\u001b[39m salem\u001b[38;5;241m.\u001b[39mcheck_crs(rgi_entity\u001b[38;5;241m.\u001b[39mcrs)\n\u001b[1;32m   2648\u001b[0m rgi_entity \u001b[38;5;241m=\u001b[39m rgi_entity\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/oggm/utils/_workflow.py:3310\u001b[0m, in \u001b[0;36mGlacierDirectory._read_shapefile_from_path\u001b[0;34m(cls, fp)\u001b[0m\n\u001b[1;32m   3307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mPARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_compression\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   3308\u001b[0m         fp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 3310\u001b[0m shp \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(fp)\n\u001b[1;32m   3312\u001b[0m \u001b[38;5;66;03m# .properties file is created for compressed shapefiles. github: #904\u001b[39;00m\n\u001b[1;32m   3313\u001b[0m _properties \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtar://\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.properties\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/geopandas/io/file.py:289\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_fiona(\n\u001b[1;32m    290\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/geopandas/io/file.py:316\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m reader(path_or_bytes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[0;32m--> 316\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m             \u001b[38;5;66;03m# fiona 1.9+\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/site-packages/fiona/collection.py:307\u001b[0m, in \u001b[0;36mCollection.crs_wkt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a WKT string.\"\"\"\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crs_wkt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crs_wkt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mget_crs_wkt()\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crs_wkt\n",
      "File \u001b[0;32mfiona/ogrext.pyx:869\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.get_crs_wkt\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/oggm_env/lib/python3.12/logging/__init__.py:1517\u001b[0m, in \u001b[0;36mLogger.debug\u001b[0;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m=\u001b[39m _checkLevel(level)\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanager\u001b[38;5;241m.\u001b[39m_clear_cache()\n\u001b[0;32m-> 1517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdebug\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;124;03m    Log 'msg % args' with severity 'DEBUG'.\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;124;03m    logger.debug(\"Houston, we have a %s\", \"thorny problem\", exc_info=True)\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misEnabledFor(DEBUG):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initiate glacier directory task for each glacier\n",
    "base_url = 'https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.6/L3-L5_files/2023.3/elev_bands/W5E5_spinup'\n",
    "gdirs = workflow.init_glacier_directories(rgi_ids,\n",
    "                                           from_prepro_level=5,\n",
    "                                           prepro_base_url=base_url,\n",
    "                                         prepro_border=80)\n",
    "## we have a problem with the 10th glacier.  Why is OGGM not continuing?\n",
    "## Try: running this in a for loop, and/or removing problem glaciers\n",
    "## this is up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa409c3d-7273-4a51-9001-3c306c920246",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e3b8a-68d0-4e7c-aefc-4316fe6cc06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdirs = []\n",
    "# for r in rgi_ids:\n",
    "#     try:\n",
    "#         gdir_temp = workflow.init_glacier_directories(r,\n",
    "#                                                    from_prepro_level=5,\n",
    "#                                                    prepro_base_url=base_url,\n",
    "#                                                  prepro_border=80)\n",
    "#         gdirs.append(gdir_temp)\n",
    "#     except:\n",
    "#         print('Failed for {}'.format(r))\n",
    "#         continue\n",
    "\n",
    "## Does not make correct format of gdirs for later use; also doesn't report any errors\n",
    "## better luck next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a75d05-3f67-4811-abae-12eeaf626eda",
   "metadata": {},
   "source": [
    "# Step 5. Initiate climate runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb0871-d252-479e-a86f-d9a09ffe9c5c",
   "metadata": {},
   "source": [
    "### I. Run constant climate commitment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4150501-6ee3-41e8-a8dd-f4c70f5f42c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initiate run_with_hydro using constant climate\n",
    "# I assume this stays the same?\n",
    "# Changed 'gdir' to 'gdirs'\n",
    "for g in gdirs:\n",
    "    file_id = '_ct'\n",
    "    tasks.run_with_hydro(g, run_task=tasks.run_constant_climate, nyears=100, y0=2014, halfsize=5, store_monthly_hydro=True, \n",
    "                     output_filesuffix=file_id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5770c-1635-4150-8e75-f04e6a76c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data from constant climate run and compile run output\n",
    "import datetime\n",
    "output_path = '~/Documents/summer24/{}-ct_compiled_output.nc'.format(datetime.date.today()) \n",
    "new_ds = utils.compile_run_output(gdirs, input_filesuffix=file_id, path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7fef32-4dee-4e80-9bf5-5b67bf3a2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the glacier data from above (only when data has been saved)\n",
    "export_date = '2024-06-19'\n",
    "input_path = '~/Documents/summer24/{}-ct_compiled_output.nc'.format(export_date)\n",
    "ct_ds = xr.open_dataset(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a9314-ba0b-43b4-85c5-57c21722f813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the new dataset\n",
    "ct_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49c182-4f63-4318-9aac-cceae295d3e7",
   "metadata": {},
   "source": [
    "### a. Historical run for reference climate period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af809d75-8244-4dff-9387-df5761249b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the historical period with a fixed geometry spinup\n",
    "for g in gdirs:\n",
    "    file_id = '_hist_hydro'\n",
    "    tasks.run_with_hydro(g, run_task=tasks.run_from_climate_data,\n",
    "                         fixed_geometry_spinup_yr=1990,  # this tells to do spinup\n",
    "                         ref_area_from_y0=True,  # \n",
    "                         store_monthly_hydro=True,\n",
    "                         output_filesuffix=file_id);\n",
    "# I think i have to run this every time I start the kernel again so file_id hist_hydro exists for gcm use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8638a6a-4752-487d-b3b5-4a5f8200c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data from historic climate run and compile run output\n",
    "import datetime\n",
    "output_path = '~/Documents/summer24/{}-hist_hydro_compiled_output.nc'.format(datetime.date.today()) \n",
    "new_ds = utils.compile_run_output(gdirs, input_filesuffix=file_id, path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9177b05-5cb9-46dd-8834-c9d32c748eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the glacier data from above (only when data has been saved)\n",
    "export_date = '2024-06-19'\n",
    "input_path_hist = '~/Documents/summer24/{}-hist_hydro_compiled_output.nc'.format(export_date)\n",
    "hist_ds = xr.open_dataset(input_path_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb6610-a867-4103-a282-d8c01ce74a37",
   "metadata": {},
   "source": [
    "### b. Projection run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168747b-c3f7-4cd5-ac5d-3cf63ea0277c",
   "metadata": {},
   "source": [
    "<b> Remember: you need to change the GCM for bp and bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfdac93-202c-45e3-b590-77f751a1fa67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Process climate data for each GCM \n",
    "\n",
    "# # name the gcm that is currently used\n",
    "# # CHANGE GCM TO DOWNLOAD A DIFFERENT ONE\n",
    "# current_gcm = 'CCSM4'\n",
    "\n",
    "# # identify which gcms ('poorly behaved') have only 3 rcp scenarios instead of 4\n",
    "# poorly_behaved = ['CNRM-CM5', 'CanESM2', 'MPI-ESM-LR']\n",
    "\n",
    "# # import climate data from where it is stored within oggm\n",
    "# ## Remember to change name of gcm each time this is run! \n",
    "# ## Note: I have tried to make this more efficient, but can't get the {} to work right\n",
    "# from oggm.shop import gcm_climate\n",
    "# bp = 'https://cluster.klima.uni-bremen.de/~oggm/cmip5-ng/pr/pr_mon_{}_{}_r1i1p1_g025.nc' #precipitation\n",
    "# bt = 'https://cluster.klima.uni-bremen.de/~oggm/cmip5-ng/tas/tas_mon_{}_{}_r1i1p1_g025.nc' #temperature\n",
    "\n",
    "# # process climate data for each rcp scenario\n",
    "# if current_gcm in poorly_behaved:\n",
    "#     for rcp in ['rcp26', 'rcp45', 'rcp85']:\n",
    "#         # Download the files\n",
    "#         ft = utils.file_downloader(bt.format(current_gcm, rcp))\n",
    "#         fp = utils.file_downloader(bp.format(current_gcm, rcp))\n",
    "#         # bias correct them\n",
    "#         for g in gdirs:\n",
    "#             workflow.execute_entity_task(gcm_climate.process_cmip_data, [g],\n",
    "#                                          filesuffix='_{}_{}'.format(current_gcm, rcp),  # recognize the climate file for later\n",
    "#                                          fpath_temp=ft,  # temperature projections\n",
    "#                                          fpath_precip=fp,  # precip projections\n",
    "#                                              );\n",
    "# else:\n",
    "#     for rcp in ['rcp26', 'rcp45', 'rcp60', 'rcp85']:\n",
    "#         # Download the files\n",
    "#         ft = utils.file_downloader(bt.format(current_gcm, rcp))\n",
    "#         fp = utils.file_downloader(bp.format(current_gcm, rcp))\n",
    "#         # bias correct them\n",
    "#         for g in gdirs:\n",
    "#             workflow.execute_entity_task(gcm_climate.process_cmip_data, [g],\n",
    "#                                          filesuffix='_{}_{}'.format(current_gcm, rcp),  # recognize the climate file for later\n",
    "#                                          fpath_temp=ft,  # temperature projections\n",
    "#                                          fpath_precip=fp,  # precip projections\n",
    "#                                              );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963075f-5770-4f4a-8f13-9effcadc60e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Run the model with hydrologic output for each rcp scenario\n",
    "# if current_gcm in poorly_behaved:\n",
    "#     for g in gdirs:\n",
    "#         for rcp in ['rcp26', 'rcp45', 'rcp85']:\n",
    "#             rid = '_{}_{}'.format(current_gcm, rcp)\n",
    "#             tasks.run_with_hydro(g, run_task=tasks.run_from_climate_data,\n",
    "#                                  climate_filename='gcm_data',  # use gcm_data, not climate_historical\n",
    "#                                  climate_input_filesuffix=rid,  # use the chosen scenario (gcm and rcp)\n",
    "#                                  init_model_filesuffix='_hist_hydro',  # start using hist data\n",
    "#                                  ref_geometry_filesuffix='_hist_hydro',  # also use this as area reference\n",
    "#                                  ref_area_from_y0=True,  # and keep the same reference area as for the historical simulations\n",
    "#                                  output_filesuffix=rid,  # recognize the run for later\n",
    "#                                  store_monthly_hydro=True,  # add monthly diagnostics\n",
    "#                                  );\n",
    "# else:\n",
    "#     for g in gdirs:\n",
    "#         for rcp in ['rcp26', 'rcp45', 'rcp60', 'rcp85']:\n",
    "#             rid = '_{}_{}'.format(current_gcm, rcp)\n",
    "#             tasks.run_with_hydro(g, run_task=tasks.run_from_climate_data,\n",
    "#                                  climate_filename='gcm_data',\n",
    "#                                  climate_input_filesuffix=rid, \n",
    "#                                  init_model_filesuffix='_hist_hydro', \n",
    "#                                  ref_geometry_filesuffix='_hist_hydro',  \n",
    "#                                  ref_area_from_y0=True, \n",
    "#                                  output_filesuffix=rid, \n",
    "#                                  store_monthly_hydro=True, \n",
    "#                                  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a339a6-8e72-4834-b171-944ac1bfd9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ds_nor = utils.compile_run_output(gdirs, input_filesuffix=rid)\n",
    "# new_ds_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d4775-15fa-43ea-a7a8-b97d9748843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export data from climate run and compile run output\n",
    "# import datetime\n",
    "# if current_gcm in poorly_behaved:\n",
    "#     for rcp in ['rcp26', 'rcp45', 'rcp85']:\n",
    "#         rid = '_{}_{}'.format(current_gcm, rcp) #same rid as in step above\n",
    "#         output_path = '~/Documents/summer24/{}-gcm_data_{}_{}_compiled_output.nc'.format(datetime.date.today(), current_gcm, rcp) #define name for file \n",
    "#         new_ds = utils.compile_run_output(gdirs, input_filesuffix=rid, path=output_path) #compile all rcp outputs into one file\n",
    "# else:\n",
    "#     for rcp in ['rcp26', 'rcp45', 'rcp60', 'rcp85']:\n",
    "#         rid = '_{}_{}'.format(current_gcm, rcp)\n",
    "#         output_path = '~/Documents/summer24/{}-gcm_data_{}_{}_compiled_output.nc'.format(datetime.date.today(), current_gcm, rcp) \n",
    "#         new_ds = utils.compile_run_output(gdirs, input_filesuffix=rid, path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce04acb-064d-44a6-9d40-3d1d9eb5a5e7",
   "metadata": {},
   "source": [
    "## II. Run CMIP6 projection run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414bad2-6d84-4e74-8cc0-2cad73f3387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this something I need to/should do? https://docs.oggm.org/en/latest/climate-data.html\n",
    "from oggm.tasks import process_w5e5_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db04f11-9692-4deb-beb9-b4e63b5b9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the issue here is with ssp245, not the models; why? probably in oggm somewhere but that will take some digging\n",
    "\n",
    "from oggm.shop import gcm_climate\n",
    "all_members = ['gfdl-esm4_r1i1p1f1', 'mpi-esm1-2-hr_r1i1p1f1', 'mri-esm2-0_r1i1p1f1',\n",
    "               'ipsl-cm6a-lr_r1i1p1f1', 'ukesm1-0-ll_r1i1p1f2']\n",
    "\n",
    "# Download the three main SSPs\n",
    "for member in all_members:\n",
    "    for ssp in ['ssp126', 'ssp370', 'ssp585']:\n",
    "        # bias correct them\n",
    "        workflow.execute_entity_task(gcm_climate.process_monthly_isimip_data, gdirs, # isimip is where the problem is; ssp245 won't work with this; see https://www.isimip.org/documents/413/ISIMIP3b_bias_adjustment_fact_sheet_Gnsz7CO.pdf\n",
    "                                     ssp = ssp,\n",
    "                                     # gcm member -> you can choose another one\n",
    "                                     member=member,\n",
    "                                     # recognize the climate file for later\n",
    "                                     output_filesuffix=f'_ISIMIP3b_{member}_{ssp}'\n",
    "                                     );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d906f-c513-46b4-8187-f930079eaf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the model with hydrologic output for each rcp scenario\n",
    "# for g in gdirs:\n",
    "#         for ssp in ['ssp126', 'ssp370', 'ssp585']:\n",
    "#             rid = '_{}_{}'.format(member, ssp)\n",
    "#             tasks.run_with_hydro(g, run_task=tasks.run_from_climate_data,\n",
    "#                                  climate_filename='gcm_data',\n",
    "#                                  climate_input_filesuffix=rid, \n",
    "#                                  init_model_filesuffix='_hist_hydro', \n",
    "#                                  ref_geometry_filesuffix='_hist_hydro',  \n",
    "#                                  ref_area_from_y0=True, \n",
    "#                                  output_filesuffix=rid, \n",
    "#                                  store_monthly_hydro=True, \n",
    "#                                  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a402de-bbad-4ea8-877c-5a625e4f35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From OGGM; see how this differs from og code above\n",
    "# Run the model with hydrologic output for each rcp scenario\n",
    "for ssp in ['ssp126', 'ssp370', 'ssp585']: # add ssp245\n",
    "    rid = f'_ISIMIP3b_{member}_{ssp}' # I don't know how/if this will affect the pathway in the next notebook?\n",
    "    workflow.execute_entity_task(tasks.run_with_hydro, gdirs,\n",
    "                             run_task=tasks.run_from_climate_data, ys=2020,\n",
    "                             # use gcm_data, not climate_historical\n",
    "                             climate_filename='gcm_data',\n",
    "                             # use the chosen scenario\n",
    "                             climate_input_filesuffix=rid,\n",
    "                             # this is important! Start from 2020 glacier\n",
    "                             init_model_filesuffix='_spinup_historical',\n",
    "                             # recognize the run for later\n",
    "                             output_filesuffix=rid,\n",
    "                             # add monthly diagnostics\n",
    "                             store_monthly_hydro=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c9fa02-e87d-4796-9ca7-4edeb6106944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is unchanged\n",
    "new_ds_nor = utils.compile_run_output(gdirs, input_filesuffix=rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0e9cc-4fa1-4458-8272-6a055f6754b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export data from climate run and compile run output\n",
    "# import datetime\n",
    "# for ssp in ['ssp126', 'ssp370', 'ssp585']:\n",
    "#         rid = '_{}_{}'.format(member, ssp) #same rid as in step above\n",
    "#         output_path = '~/Documents/summer24/{}-gcm_data_{}_{}_compiled_output.nc'.format(datetime.date.today(), member, ssp) #define name for file \n",
    "#         new_ds = utils.compile_run_output(gdirs, input_filesuffix=rid, path=output_path) #compile all rcp outputs into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ef48a-13de-4c91-a8b7-424e1e486b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes explained by ChatGPT; again, unsure how this will affect pathway\n",
    "# Export data from climate run and compile run output\n",
    "import datetime\n",
    "for ssp in ['ssp126', 'ssp370', 'ssp585']:\n",
    "    # Update the rid format to match the first cell\n",
    "    rid = f'_ISIMIP3b_{member}_{ssp}'\n",
    "    # Define the output path with proper path handling\n",
    "    output_path = os.path.expanduser(f'~/Documents/summer24/{datetime.date.today()}-gcm_data_{member}_{ssp}_compiled_output.nc')\n",
    "    # Compile all rcp outputs into one file\n",
    "    new_ds = utils.compile_run_output(gdirs, input_filesuffix=rid, path=output_path) #compile all rcp outputs into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a576455-c077-4cd6-bb4d-29c404c04814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OGGM said to do this; not sure if its necessary, but at least it works\n",
    "# Create the figure\n",
    "f, ax = plt.subplots(figsize=(18, 7), sharex=True)\n",
    "# Loop over all scenarios\n",
    "for i, ssp in enumerate(['ssp126', 'ssp370', 'ssp585']):\n",
    "    file_id = f'_ISIMIP3b_{member}_{ssp}'\n",
    "    # Open the data, gdirs[0] correspond to Hintereisferner.\n",
    "    with xr.open_dataset(gdirs[0].get_filepath('model_diagnostics', filesuffix=file_id)) as ds:\n",
    "        # Load the data into a dataframe\n",
    "        ds = ds.isel(time=slice(0, -1)).load()\n",
    "\n",
    "    # Select annual variables\n",
    "    sel_vars = [v for v in ds.variables if 'month_2d' not in ds[v].dims]\n",
    "    # And create a dataframe\n",
    "    df_annual = ds[sel_vars].to_dataframe()\n",
    "\n",
    "    # Select the variables relevant for runoff.\n",
    "    runoff_vars = ['melt_off_glacier', 'melt_on_glacier', 'liq_prcp_off_glacier', 'liq_prcp_on_glacier']\n",
    "    # Convert to mega tonnes instead of kg.\n",
    "    df_runoff = df_annual[runoff_vars].clip(0) * 1e-9\n",
    "    # Sum the variables each year \"axis=1\", take the 11 year rolling mean and plot it.\n",
    "    df_roll = df_runoff.sum(axis=1).rolling(window=11, center=True).mean()\n",
    "    df_roll.plot(ax=ax, label=ssp, color=sns.color_palette(\"rocket\")[i])\n",
    "\n",
    "ax.set_ylabel('Annual runoff (Mt)'); ax.set_xlabel('Year'); plt.title(gdirs[0].rgi_id); plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16590a2d-46ef-4f9e-8e8d-8ad1a89c653f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
